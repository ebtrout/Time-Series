---
title: "TSHW4 Draft"
author: "Blue Team 16"
output:
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: true
    df_print: paged
---

```{r, include=FALSE}
library(tidyverse)
library(rstudioapi)
library(tsibble)
library(fabletools)
library(scales)
library(fable)
library(forecast)
library(imputeTS)
library(feasts)
library(here)
setwd(here())
```

# Setup
```{r}
# Reading in the data
energy <- read.csv("data/hrl_load_metered.csv")
energyTest <- read.csv("data/hrl_load_metered - test1.csv")

# Duplicate Spring removal
energy <- energy %>% group_by(datetime_beginning_ept) %>% 
  summarize(mw = mean(mw, na.rm = T),.groups = "drop") %>% 
  rename("time" = datetime_beginning_ept) 

energyTest <- energyTest %>% 
  group_by(datetime_beginning_ept) %>% 
  summarize(mw = mean(mw, na.rm = T),.groups = "drop") %>% 
  rename("time" = datetime_beginning_ept) 

# Fixing time values 
energy$time <- as.POSIXct(energy$time,format = "%m/%d/%y %H:%M",tz = "America/New_York")

energyTest$time <- as.POSIXct(energyTest$time,format = "%m/%d/%y %H:%M",tz = "America/New_York")

# Converting to Tsibble and filling gaps

energy <- energy %>% as_tsibble(index = time) %>% fill_gaps()

energyTest <- energyTest %>% as_tsibble(index = time) %>% fill_gaps()

# Imputing fall
energy <- energy %>% na_interpolation(option = "spline")

energyTest <- energyTest %>% na_interpolation(option = "spline")

## DUMMY VARIABLE MODEL HELPERS

# Add set indicator for separating
energy <- energy %>% mutate(set = "train")
energyTest <- energyTest %>% mutate(set = "test")

# Add all helper variables and combine sets to ensure factor levels are present throughout
energyCombined <- bind_rows(energy,energyTest) %>% 
  mutate(month = factor(month(time))) %>%
  mutate(hour = factor(hour(time))) %>% 
  mutate(dayOfWeek = factor(wday(time))) %>% 
  mutate(year = factor(year(time))) %>% 
  mutate(day = factor(day(time)))

# Separate sets back out
energy <- energyCombined %>% filter(set == "train")
energyTest <- energyCombined %>% filter(set == "test")
```
# Investigating Series

## Stationarity
```{r}
gg_tsdisplay(energy[1:15000,])
```
  Very doubtful of stationary, this is real data

```{r}
ndiffs(energy$mw)
```
All models perform better with differences, and statistical tests indicate we should be taking a first difference. All plots and models are on differenced data going forward.



## Selecting Lags
```{r}
ggAcf(difference(energy$mw),lag.max = 100)

ggPacf(difference(energy$mw),lag.max = 100)
```
PACF:Seeing exponential decrease in PACF aside from two spikes at lags 1, 2, and 24. Thinking p = 2, and P = 1 for a Basic Arima model.  

ACF: Large spikes throughout. Hard to tell with such complex seasonality. Would say q = 3 to account for the large spikes at 1,2,3, and Q = 7, because looking back any farther than a week feels like it wouldnt be sound. 

# Exponential Smoothing Models

```{r,eval = F}
# Create all Exponential Smoothing models 
etsFit <- energy %>% mutate(mw = difference(mw))
  model(
    `SES` = ETS(mw ~ error("A") + trend("N") + season("N")),
    `Linear` = ETS(mw ~ error("A") + trend("A") + season("N")),
    `Damped Linear` = ETS(mw ~ error("A") + trend("Ad") + season("N")),
    `Holt-Winters Additive` = ETS(mw ~ error("A") + trend("A") + season("A")),
    `Holt-Winters' Multiplicative` = ETS(mw ~ error("M") + trend("A") + season("M")),
    `Holt-Winters' Multiplicative Damped` = ETS(mw ~ error("M") + trend("Ad") + season("M"))
  )
  
```

```{r,eval = F}
# Saving the file so I dont have to run these again...
save(etsFit,file = "etsFit.RData")
```

# Deterministic models

## Seasonal ARIMA 
```{r,eval = F}
# Basic Seasonal Search 

# Built according to the lag chart investigation

seasonalArima <- energy %>% 
  model(
    search1 = ARIMA(mw ~pdq(d = 1) + PDQ(D = 0),stepwise = T),
    seasonalArima1 = ARIMA(mw ~pdq(p = 2,d = 1,q = 3) + PDQ(P = 1,D = 0,Q = 7)),
    seasonalArima2 = ARIMA(mw ~pdq(p = 2,d = 1,q = 3) + PDQ(P = 1,D = 0,Q = 5)),
    search2 = ARIMA(mw ~pdq(p = 2,d = 1,q = 3) + PDQ(D = 0),stepwise = F),
  )
# Saving the file so I dont have to run these again...
save(seasonalArima,file = "seasonalArima.RData")
```

Best models! Who would've thought building models based on the lag charts would be better than the auto search feature.

## Fourier
```{r}
 time <- Sys.time()
# Throwing the kitchen sink at "complex seasonality" adjustments
fourierModels <- energy %>% 
  model(
    dayMonthWeekYear1 = 
      ARIMA(
        mw ~ pdq(3,1,3) + PDQ(D=0) + 
              fourier(period = 24,K = 3) + 
              fourier(period = 24 * 30,K= 2) + 
              fourier(period = 24 * 365, K = 2)
    ) 
  )
```

Disappointed in these... None of these were any good compared to other models.  
Want to ask Dr. Simmons a few questions bc this is the exact method the guy who wrote the textbook on this package used to model electric use data, and it performed amazingly.

### Newer dummy variable models
```{r,eval = F}
## Models  are split into chunks to prevent 
## loss of progress due to crashes / reboots, etc.

# Dummy variables :DDDDD
print(Sys.time())
time <- Sys.time()
# Model 1
dummyArima1 <- energy %>% 
  model(
    HourMonthSearch = ARIMA(
      mw ~ 1 + hour + month + 
        pdq(d = 1) + PDQ(D = 0)
    )
  )

# 2.7 hours
print("dummyArima1 Saved")
print(Sys.time() - time)
save(dummyArima1,file = "dummyArima1.RData")


time <- Sys.time()
# Model 2
dummyArima2 <- energy %>% 
  model(
    HourMonthdayOfWeekSearch = ARIMA(
      mw ~ 1 + hour + month + dayOfWeek + 
        pdq(d = 1) + PDQ(D = 0)
    )
  )

# 5.5 hours
print("dummyArima2 Saved")
print(Sys.time() - time)
save(dummyArima2,file = "dummyArima2.RData")

# Lots more here were run, but alot just would output as NULL MODEL 
```
Similarly disapointed... For the amount of run time spent (and bugs encountered with forecasting making me re run these multiple times) the predictive power just wasnt there.

# Model Eval
## Loading in Models
```{r}
load("fourierModels.RData")

load("etsFit.RData")

load("seasonalArima.RData")



load("dummyArima1.RData")
load("dummyArima2.RData")
load("dummyArima.RData")
```


```{r,include = F}
# Making an older version of the test dataset in order to forecast with an 
# earlier version of dummy variable models
energyTest2 <- energyTest %>% select(-day) %>% rename("day" = dayOfWeek)
```

## Model Glancing

```{r}
models <- bind_cols(dummyArima,dummyArima1,dummyArima2,etsFit,seasonalArima,fourierModels)

models %>% glance() %>% select(.model,"AICc") %>% arrange(AICc)
```
Seasonal ARIMA models built according to lag charts fit the data the best.  
Dummy variable models are the second best option, but are significantly worse.

## White Noise Eval
```{r}
# Only looking at the top 4 models, arranged by AICc

# SeasonalArima1
models %>% select(seasonalArima1) %>% gg_tsresiduals() + ggtitle("SeasonalArima1")
models %>% select(seasonalArima1) %>% residuals() %>% ggPacf() + ggtitle("SeasonalArima1 Pacf")

# SeasonalArima2
models %>% select(seasonalArima2) %>% gg_tsresiduals() + ggtitle("SeasonalArima2")
models %>% select(seasonalArima2) %>% residuals() %>% ggPacf() + ggtitle("SeasonalArima2 Pacf")


# Dummy variable dayOfWeek, Hour of Day
models %>% select(dayHour) %>% gg_tsresiduals() + ggtitle("dayHour")
models %>% select(dayHour) %>% residuals() %>% ggPacf() + ggtitle("dayHour Pacf")

# Dummy varaible, dayOfWeek, Hour of Day, and Month 
models %>% select(HourMonthdayOfWeekSearch) %>% gg_tsresiduals() + ggtitle("HourMonthdayOfWeek")
models %>% select(HourMonthdayOfWeekSearch) %>% residuals() %>% ggPacf() + ggtitle("HourMonthdayOfWeek Pacf")


# Exponential Smoothing Model
etsFit %>% select("Holt-Winters' Multiplicative") %>% gg_tsresiduals() + ggtitle("Exponential Smoothing")
etsFit %>% select("Holt-Winters' Multiplicative") %>% residuals() %>% ggPacf() + ggtitle("Exponential Smoothing Pacf")
```
I can run white noise tests with the ljung box test, but there is so much remaining autocorrelation that the p-values would be terrible. With real data like this, especially such complex data, achieving white noise is almost impossible (verified by LaBarr, but I can ask him if he wants it included)

## Model Forecasting 
```{r}
fourierForecasts <- fourierModels %>% fabletools::forecast(new_data = energyTest)

etsForecasts <- etsFit %>% fabletools::forecast(new_data = energyTest) 

seasonalForecasts <- seasonalArima %>% fabletools::forecast(h= nrow(energyTest))

dummyForecasts1 <- dummyArima1 %>% fabletools::forecast(new_data = energyTest)

dummyForecasts2 <- dummyArima2 %>% fabletools::forecast(new_data = energyTest)

# Old dummy variable models, old dataset
dummyForecasts <- dummyArima %>% fabletools::forecast(new_data = energyTest2)

# Combining the forecasts
forecasts <- bind_rows(dummyForecasts,dummyForecasts1,dummyForecasts2,fourierForecasts,etsForecasts,seasonalForecasts)
```

## MAPE and MAE
```{r}
accuracies <- fabletools::accuracy(forecasts,energyTest) 

accuracies <- accuracies[,c(".model","MAPE","MAE")] %>% arrange(MAPE)

print(accuracies)
```

## Forecast Graphs
```{r}
# Useful models, THIS WILL CHANGE
models <- c("seasonalArima2","seasonalArima1","dayHour","HourMonthdayOfWeekSearch","Holt-Winters' Multiplicative")

modelTitles <- c("Seasonal Arima 5 Seasonal Lags","Seasonal Arima 7 Seasonal Lags","DummyVar dayOfWeek + hour","DummyVar hour + dayOfWeek+ month","Exponential Smoothing Model")


# Loops through each of the model names and graphs forecasted versus actual
for (i in 1:length(models)) {
  graphForecast <- forecasts %>% filter(.model == models[i])
  graphForecast <- graphForecast$.mean
  graphDF <- data.frame(
    forecast = graphForecast,
    actual = energyTest$mw,
    time = energyTest$time
  )
  mape <- accuracies %>% filter(.model == models[i]) %>% select(MAPE) %>% round(2)
  
  plot <- ggplot(data = graphDF, aes(x = time)) + 
  geom_line(aes(y = forecast, color = "Model A Forecast"), linewidth = 1.2,alpha =.7) + 
  geom_line(aes(y = actual,color = "Observed"),linetype = "twodash",linewidth = 1.5) + 
  scale_color_manual(values = c("Observed" = "black", "Model A Forecast" = "orange")) + 
  scale_y_continuous(labels = comma) + 
  labs(colour = "",
       title = paste0("Forecasted MW Usage for ",modelTitles[i],""),
       subtitle = paste0("09/13/2024- 09/19/2024\n","MAPE: ",mape,"\n"),
       y ="Hourly\nMW",
       x = "") + 
  theme_classic() + 
  theme(axis.title.y = element_text(angle = 0,vjust = .5))
  
  print(plot)
}
```

# Main Takeaways

It looks like regular seasonal models with just pdq, PDQ are performing the best.  
Want to ask the professors how to improve the fourier and dummy var models, but that can definitely be for future homeworks. Also want to do some stochastic approaches.  
All models show strong correlation with data points directly before and after seasonal lags (i.e. 23 and 25). Want to know if there is any way to account for that without including a million rank deficient terms to catch that signal.  
White noise looks pretty good! There is still a ton of signal these models arent capturing according to pacf and acf plots of the residuals. None of my attempts had pure white noise, but that makes sense with real, complicated data.

